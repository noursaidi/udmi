from collections.abc import Callable
from typing import Any
import copy
import datetime
import glob
import json
import json
import os
from pathlib import Path
import random
import re
import shutil
import shutil
import signal
import ssl
import subprocess
import sys
import time
import time
from typing import Any
from typing import Iterator
import contextlib

import pytest

KEYS_TO_REDACT = ["timestamp", "version", "operation"]
REDACTED_VALUE = "redacted"

SITE_PATH = os.getenv("SITE_PATH") if os.getenv("SITE_PATH") else "."


devices_list = [
    x.parent.stem
    for x in Path(SITE_PATH).glob(
        os.path.join("udmi/devices/*/rsa_private.pem")
    )
]


def until_true(func: Callable, message: str, **kwargs):
  """Blocks until given func returns True

  Raises:
    Exception if timeout has elapsed
  """
  timeout = kwargs.get("timeout", 0)
  interval = kwargs.get("interval", 0.1)

  expiry_time = time.time() + timeout
  while time.time() < expiry_time or timeout == 0:
    if func():
      return True
    if "do" in kwargs:
      kwargs["do"]()
    time.sleep(interval)
  raise Exception(f"Timed out waiting {timeout}s for {message}")


def dict_paths(thing: dict[str: Any], stem: str = "") -> Iterator[str]:
  """Returns json paths (in dot notation) from a given dictionary."""
  for k, v in thing.items():
    path = f"{stem}.{k}" if stem else k
    if isinstance(v, dict):
      yield from dict_paths(v, path)
    else:
      yield path


def normalize_keys(target: dict[Any: Any], replacement, *args):
  """ Replaces value of given keys in a nested dictionary with given replacement."""
  for k, v in target.items():
    if k in args:
      target[k] = replacement
    elif isinstance(v, dict):
      normalize_keys(v, replacement, *args)
  return target


def run(cmd: str) -> subprocess.CompletedProcess:
  """ Runs the given shell commnd and wait for it to complete """
  return subprocess.run(cmd, shell=True, capture_output=True, cwd=SITE_PATH)


def is_registrar_done() -> bool:
  run("git pull")
  history_files = list(Path(SITE_PATH).glob("udmi/history/*.json"))

  # we've deleted the history so there will only be one file
  assert len(history_files) <= 1

  if history_files:
    # currently file is empty at start, and only written to at the end
    return history_files[0].stat().st_size > 0


@pytest.fixture
def random_size_site_model():

  #devices_count = random.randint(1, 40)
  devices_count = 10
  device_prefix = "DDC"
  base_device = f"{device_prefix}-1"

  metadata_path = os.path.join(
      SITE_PATH, "udmi/devices", base_device, "metadata.json"
  )
  public_key_file_path = os.path.join(
      SITE_PATH, "udmi/devices", base_device, "rsa_public.pem"
  )
  private_key_file_path = os.path.join(
      SITE_PATH, "udmi/devices", base_device, "rsa_private.pem"
  )

  with open(metadata_path, encoding="utf-8") as f:
    base_metadata = json.load(f)

  print(base_metadata)

  desired_devices = [f"{device_prefix}-{i}" for i in range(2, devices_count)]

  existing_devices = [os.stem for x in Path(SITE_PATH).glob("udmi/devices/*")]
  for existing_device in existing_devices:
    if existing_device != base_device:
      shutil.rmtree(os.path.join(SITE_PATH, "udmi/devices", existing_device))

  for device_id in desired_devices:

    device_path = os.path.join(SITE_PATH, "udmi/devices", device_id)
    metadata = normalize_keys(copy.copy(base_metadata), device_id, "name")
    print(metadata)

    os.mkdir(device_path)

    with open(
        os.path.join(device_path, "metadata.json"), mode="w", encoding="utf-8"
    ) as f:
      json.dump(metadata, f)

    shutil.copy(
        public_key_file_path, os.path.join(device_path, "rsa_public.pem")
    )
    shutil.copy(
        private_key_file_path, os.path.join(device_path, "rsa_private.pem")
    )
  yield


def git_flow():
  run("git pull")
  run(f"bin/registrar {PATH}")
  # delete history for ease of tracking
  
  with contextlib.suppress(FileNotFoundError):
    shutil.rmtree(os.path.join(SITE_PATH, "udmi/history/"))


  Path(os.path.join(SITE_PATH, "run-registrar")).touch()

  run(f"git add -A")
  run(f'git commit -m "run registrar"')
  run(f"git push -o nokeycheck")

  # wait until registrar is complete
  until_true(is_registrar_done, "registrar to complete", timeout=3600)


def proxy_id(x: int) -> str:
  return "".join([chr[int(x)] for x in str(x)]).rjust(4, "A")


def gateway_site_model():
  # generate random gateway site model
  gateways = {
      f"GAT-{i}": [f"{proxy_id(i)}-{x}" for x in range(1, random.randint(2, 5))]
      for i in range(1, random.randint(2, 5))
  }


def test_sequencer():



def test_random_site_model(random_size_site_model):
  git_flow()


def test_random_gateway(random_size_site_model):
  git_flow()


@pytest.mark.parametrize("device_id", devices_list)
def test_device(device_id):
  site_path = os.path.join(SITE_PATH, "udmi/")
  project_id = "bos-platform-prod"

  with open(
      os.path.join(
          site_path, "devices", device_id, "out/generated_config.json"
      ),
      encoding="utf-8",
  ) as f:
    expected_config = json.load(f)

  device = MqttClient(site_path, project_id, device_id)

  until_true(
      lambda: device.config(device_id) is not None,
      "device recieved config",
      do=lambda: device.client.loop(),
      timeout=5,
  )

  config = copy.deepcopy(device.config(device_id))

  # timestamp and version gets set by the cloud so normalise these
  # 'operation' because new?
  normalized_config = normalize_keys(config, REDACTED_VALUE, *KEYS_TO_REDACT)
  normalized_expected = normalize_keys(
      expected_config, REDACTED_VALUE, *KEYS_TO_REDACT
  )

  assert normalized_config == normalized_expected

  metadata_path = os.path.join(site_path, "devices", device_id, "metadata.json")

  with open(metadata_path, encoding="utf-8") as f:
    metadata = json.load(f)

  proxy_ids = metadata.get("gateway", {}).get("proxy_ids", [])
  for proxy_id in proxy_ids:
    mid = device.attach_device(proxy_id)
    print(mid)
    until_true(
        lambda: device.puback(mid),
        f"puback for attach {proxy_id}",
        do=lambda: device.client.loop(),
        timeout=5,
    )

    device.subscribe_proxy_config(proxy_id)
    until_true(
        lambda: device.config(proxy_id) is not None,
        f"device {device_id} recieved config",
        do=lambda: device.client.loop(),
        timeout=5,
    )

    with open(
        os.path.join(
            site_path, "devices", proxy_id, "out/generated_config.json"
        ),
        encoding="utf-8",
    ) as f:
      expected_config = json.load(f)
    config = copy.deepcopy(device.config(proxy_id))

    # timestamp and version gets set by the cloud so normalise these
    # operation because last_start, new, etc
    normalized_config = normalize_keys(config, REDACTED_VALUE, *KEYS_TO_REDACT)
    normalized_expected = normalize_keys(
        expected_config, REDACTED_VALUE, *KEYS_TO_REDACT
    )
    print(normalized_config)
    print(normalized_expected)

    assert normalized_config == normalized_expected